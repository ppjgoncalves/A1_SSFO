{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import io_pkl\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from lnpy.linear import ASD\n",
    "from scipy import signal\n",
    "from scipy.io import loadmat, savemat\n",
    "from lnpy.multilinear.context.als_dense import segment_spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data, select recordings, downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "file_path = 'dataArray_complete_v2.mat'\n",
    "data = loadmat(file_path, struct_as_record=False, squeeze_me=True)\n",
    "\n",
    "# DRC stimulus\n",
    "stimulus_file_path = 'testMask.mat'\n",
    "stimulus_mat = loadmat(stimulus_file_path, struct_as_record=False, squeeze_me=True)\n",
    "stimulus = stimulus_mat['samples']*1.\n",
    "\n",
    "freq_mat = stimulus_mat['xvalues']\n",
    "min_freq = np.min(stimulus_mat['xvalues']/1e3).astype(int)\n",
    "max_freq = np.max(stimulus_mat['xvalues']/1e3).astype(int)\n",
    "\n",
    "num_freq = len(freq_mat)\n",
    "num_tim = len(stimulus[:,0])\n",
    "\n",
    "samplerate_new = stimulus_mat['samplerate']*1 #Hz\n",
    "\n",
    "# stimulus frequencies grow with column (so, assuming originally frequencies decrease with increasing column)\n",
    "stimulus = np.fliplr(stimulus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale DRC stimulus\n",
    "X_stimulus = stimulus.copy()\n",
    "if np.max(stimulus) > 1.:\n",
    "    # amplitude level with respect to 1mw  (dBm); used for transforming\n",
    "    # dB-scaled data to linear scale; max(X) <= 1 assumes that the data\n",
    "    # are already scaled linearly.\n",
    "    ind = stimulus > 0.\n",
    "    X_stimulus[ind] = 10. ** ((stimulus[ind] - np.max(stimulus[ind]))/20.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load signal powers\n",
    "signalPower_mat_ls = ['signalPower_07_v2.mat','signalPower_79-80_v2.mat','signalPower_119-120-153-154_v2.mat']\n",
    "\n",
    "varnames_ls = []\n",
    "signalPower_ls = []\n",
    "cell_id_pow_ls = []\n",
    "for f in signalPower_mat_ls:\n",
    "    signalPower = loadmat(f, struct_as_record=False, squeeze_me=True)\n",
    "    varnames1 = [str(i) for i in signalPower['resultsTable'].varnames]\n",
    "    varnames_ls.append(varnames1)\n",
    "    signalPower1 = np.vstack(signalPower['resultsTable'].data)\n",
    "    signalPower1 = np.array(signalPower1[1:,:], dtype=np.float64)\n",
    "    signalPower_ls.append(signalPower1)\n",
    "    cell_id_pow = np.vstack(signalPower['resultsTable'].data)[0,:]\n",
    "    cell_id_pow_ls.append(cell_id_pow)\n",
    "    \n",
    "varnames_mat = np.concatenate(varnames_ls)[0:7]\n",
    "signalPower_mat = np.concatenate(signalPower_ls,axis=1)\n",
    "cell_id_pow_mat = np.concatenate(cell_id_pow_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exclude recordings according to several criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude recordings for which signal power<sigma\n",
    "excl_pow = np.zeros_like(data['audIdx'])\n",
    "i = 0\n",
    "for cell_id1 in data['dataArray'][:,0]:\n",
    "    if np.any(cell_id_pow_mat==cell_id1):\n",
    "        p_signal_ctr = signalPower_mat[varnames_mat[1:]=='p_signal_ctr',cell_id_pow_mat==cell_id1][0]\n",
    "        err_signal_ctr = signalPower_mat[varnames_mat[1:]=='err_signal_ctr',cell_id_pow_mat==cell_id1][0]\n",
    "        p_signal_on = signalPower_mat[varnames_mat[1:]=='p_signal_on',cell_id_pow_mat==cell_id1][0]\n",
    "        err_signal_on = signalPower_mat[varnames_mat[1:]=='err_signal_on',cell_id_pow_mat==cell_id1][0]\n",
    "\n",
    "        if p_signal_ctr>err_signal_ctr and p_signal_on>err_signal_on:\n",
    "            excl_pow[i] = 1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of recordings to estimate STRF: 522\n"
     ]
    }
   ],
   "source": [
    "# exclude recordings according to audIdx, strfIdx, signal power<sigma, and excluding recordings\n",
    "# without significant changes in firing rates\n",
    "\n",
    "f = 'newNegPosIdcs.mat'\n",
    "rate_criteria1 = loadmat(f, struct_as_record=False, squeeze_me=True)\n",
    "rate_criteria = rate_criteria1['newNegIdx']+rate_criteria1['newPosIdx']\n",
    "\n",
    "excl_1 = data['audIdx']*data['strfIdx']*excl_pow*rate_criteria\n",
    "\n",
    "cell_id = data['dataArray'][excl_1==1,0]\n",
    "y_off_hisampling = data['dataArray'][excl_1==1,1]\n",
    "y_on_hisampling = data['dataArray'][excl_1==1,2]\n",
    "\n",
    "num_recs = len(cell_id)\n",
    "print('number of recordings to estimate STRF: '+str(num_recs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## downsample data with same sampling rate as stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1./samplerate_new\n",
    "t = np.arange(0,60,dt)\n",
    "\n",
    "y_off_ls = []\n",
    "y_on_ls = []\n",
    "downsample_fact = 2\n",
    "win = np.ones(downsample_fact)/(downsample_fact*1.)\n",
    "for i in range(num_recs):\n",
    "    filtered_y_off = signal.convolve(y_off_hisampling[i], win, mode='same')[::downsample_fact]\n",
    "    filtered_y_on = signal.convolve(y_on_hisampling[i], win, mode='same')[::downsample_fact]\n",
    "    \n",
    "    y_off_ls.append(filtered_y_off)\n",
    "    y_on_ls.append(filtered_y_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# estimate STRFs and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 15 # time lag STRF/PRF\n",
    "\n",
    "rfsize = (J, X_stimulus.shape[1])\n",
    "XX = segment_spectrogram(X_stimulus, J, order='C', prepend_zeros=True)\n",
    "\n",
    "maxiter = 100\n",
    "smooth_min = 0.5\n",
    "init_params = [7, 4, 4]\n",
    "tolerance = 1e-5\n",
    "\n",
    "pkl_dir = './strfs/'\n",
    "\n",
    "for cell_num in range(0,13):\n",
    "    strf_pklfile_path = 'strf_' + str(cell_id[cell_num]) +'.pkl'\n",
    "    file_exists = os.path.isfile(pkl_dir+strf_pklfile_path)\n",
    "\n",
    "    if not file_exists:       \n",
    "        y_off = y_off_ls[cell_num]\n",
    "        y_on = y_on_ls[cell_num]\n",
    "\n",
    "        ##################################################################################\n",
    "        # SSFO off\n",
    "        model_on_off = ASD(D=rfsize, verbose=True,maxiter=maxiter, stepsize=dt, solver='iter',\n",
    "                           optimizer='L-BFGS', smooth_min=smooth_min, init_params=init_params,\n",
    "                           tolerance=tolerance)\n",
    "        model_on_off.fit(XX, y_off)\n",
    "        model_off = copy.copy(model_on_off)\n",
    "\n",
    "        ##################################################################################\n",
    "        # SSFO on: fit STRF with same smoothing parameters as optimised when fitting SSFO off\n",
    "        model_on_off.solver = 'fixed'\n",
    "        model_on_off.fit(XX, y_on)\n",
    "        model_on = copy.copy(model_on_off)\n",
    "\n",
    "        # save into pickle file\n",
    "        strf1 = {'cell_id': cell_id[cell_num],\n",
    "                 'y_off': y_off,\n",
    "                 'y_on' : y_on,\n",
    "                 'model_off': model_off,\n",
    "                 'model_on' : model_on}\n",
    "\n",
    "        io_pkl.save_pkl(strf1,pkl_dir+strf_pklfile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
